{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geojson h5py pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " from geojson import GeometryCollection, Point, LineString\n",
    "import h5py\n",
    "import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materialize  OSM 200 Mio\n",
      "Raster Transform 4096.0\n",
      "Counting 4096.0\n",
      "resolution 4096.0\n",
      "unique 677700\n",
      "min bin sz 1\n",
      "max bin sz 241790\n",
      "mean bin sz 295.11583296443854\n",
      "std bin sz 1671.496216532221\n",
      "25th %: 6.0\n",
      "Median: 26.0\n",
      "75th %: 103.0\n",
      "Materialize  OSM 200 Mio\n",
      "Raster Transform 8192\n",
      "Counting 8192\n",
      "resolution 8192\n",
      "unique 1738582\n",
      "min bin sz 1\n",
      "max bin sz 96161\n",
      "mean bin sz 115.03627668985415\n",
      "std bin sz 607.1649429013877\n",
      "25th %: 3.0\n",
      "Median: 12.0\n",
      "75th %: 46.0\n",
      "Materialize  OSM 200 Mio\n",
      "Raster Transform 16384\n",
      "Counting 16384\n",
      "resolution 16384\n",
      "unique 4156942\n",
      "min bin sz 1\n",
      "max bin sz 32540\n",
      "mean bin sz 48.112290236428606\n",
      "std bin sz 222.04701606782206\n",
      "25th %: 2.0\n",
      "Median: 7.0\n",
      "75th %: 23.0\n",
      "Materialize  OSM 200 Mio\n",
      "Raster Transform 32768\n",
      "Counting 32768\n",
      "resolution 32768\n",
      "unique 9311414\n",
      "min bin sz 1\n",
      "max bin sz 13072\n",
      "mean bin sz 21.479014895052458\n",
      "std bin sz 83.07057141971521\n",
      "25th %: 2.0\n",
      "Median: 4.0\n",
      "75th %: 13.0\n",
      "Materialize  Titter 200 Mio\n",
      "Raster Transform 4096.0\n",
      "Counting 4096.0\n",
      "resolution 4096.0\n",
      "unique 1409058\n",
      "min bin sz 1\n",
      "max bin sz 17020560\n",
      "mean bin sz 141.93879882872102\n",
      "std bin sz 14808.259073444606\n",
      "25th %: 1.0\n",
      "Median: 1.0\n",
      "75th %: 3.0\n",
      "Materialize  Titter 200 Mio\n",
      "Raster Transform 8192\n",
      "Counting 8192\n",
      "resolution 8192\n",
      "unique 1983080\n",
      "min bin sz 1\n",
      "max bin sz 16769560\n",
      "mean bin sz 100.8532182261936\n",
      "std bin sz 12123.396004795362\n",
      "25th %: 1.0\n",
      "Median: 1.0\n",
      "75th %: 5.0\n",
      "Materialize  Titter 200 Mio\n",
      "Raster Transform 16384\n",
      "Counting 16384\n",
      "resolution 16384\n",
      "unique 2845933\n",
      "min bin sz 1\n",
      "max bin sz 15801333\n",
      "mean bin sz 70.27572328652853\n",
      "std bin sz 9497.607375873495\n",
      "25th %: 1.0\n",
      "Median: 1.0\n",
      "75th %: 5.0\n",
      "Materialize  Titter 200 Mio\n",
      "Raster Transform 32768\n",
      "Counting 32768\n",
      "resolution 32768\n",
      "unique 3987981\n",
      "min bin sz 1\n",
      "max bin sz 15769401\n",
      "mean bin sz 50.15069028663878\n",
      "std bin sz 7977.277715667396\n",
      "25th %: 1.0\n",
      "Median: 1.0\n",
      "75th %: 6.0\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File(\"/tf/pointclouds_2d/data/twitter_200mio_coords.h5\",\"r\")\n",
    "datasets = [(\"OSM 200 Mio\",\"/tf/pointclouds_2d/data/asia_200mio_coords.h5\"),(\"Titter 200 Mio\", \"/tf/pointclouds_2d/data/twitter_200mio_coords.h5\")]\n",
    "\n",
    "resolutions = [8192/2,8192,8192*2,8192*4]\n",
    "m = {}\n",
    "for ds, dsfn in datasets:\n",
    "    hf = h5py.File(dsfn,\"r\")\n",
    "\n",
    "\n",
    "    for r in resolutions:    \n",
    "        print(\"Materialize \", ds )    \n",
    "        c = hf['coords'][:];\n",
    "        print(\"Raster Transform\", r)\n",
    "        c = ((c + [180.0, 90.0])/ [360.0,180.0]*[r,r]).astype(np.int_)\n",
    "        print(\"Counting\", r)\n",
    "        x,c = np.unique(c,axis=0, return_counts=True)\n",
    "        print(\"resolution\", r)\n",
    "        print(\"unique\", len(x))\n",
    "        print(\"min bin sz\", np.min(c))\n",
    "        print(\"max bin sz\", np.max(c))\n",
    "        print(\"mean bin sz\", np.mean(c))\n",
    "        print(\"std bin sz\", np.std(c))\n",
    "        print(\"25th %:\", np.percentile(c, 25))\n",
    "        print(\"Median:\", np.median(c))\n",
    "        print(\"75th %:\", np.percentile(c, 75))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds, dsfn in datasets:\n",
    "    hf = h5py.File(dsfn,\"r\")\n",
    "    coords = hf['coords'][:10_000_000];\n",
    "    print(\"Materializing\")\n",
    "    c = coords[:1_000_000]\n",
    "    print(\"Raster Transform\")\n",
    "    c = ((c + [180.0, 90.0])/ [360.0,180.0]*[r,r]).astype(np.int_)\n",
    "    print(\"Counting\")\n",
    "    x,c = np.unique(c,axis=0, return_counts=True)\n",
    "\n",
    "\n",
    "    #abundance = {count:str(item) for item,count in zip(x,c)}\n",
    "    #print(abundance)\n",
    "    print(\"Abundance\")\n",
    "    c = np.sort(c)\n",
    "    m[ds]= c\n",
    "    c= c[::-1]\n",
    "    np.savetxt(f\"{ds}-abundance.dat\",c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
